{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "53c48e5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing libraries such as pandas for dataframes and numpy for math functions \n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "np.random.seed(0)\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "de4c3d78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'data': array([[6.3200e-03, 1.8000e+01, 2.3100e+00, ..., 1.5300e+01, 3.9690e+02,\n",
      "        4.9800e+00],\n",
      "       [2.7310e-02, 0.0000e+00, 7.0700e+00, ..., 1.7800e+01, 3.9690e+02,\n",
      "        9.1400e+00],\n",
      "       [2.7290e-02, 0.0000e+00, 7.0700e+00, ..., 1.7800e+01, 3.9283e+02,\n",
      "        4.0300e+00],\n",
      "       ...,\n",
      "       [6.0760e-02, 0.0000e+00, 1.1930e+01, ..., 2.1000e+01, 3.9690e+02,\n",
      "        5.6400e+00],\n",
      "       [1.0959e-01, 0.0000e+00, 1.1930e+01, ..., 2.1000e+01, 3.9345e+02,\n",
      "        6.4800e+00],\n",
      "       [4.7410e-02, 0.0000e+00, 1.1930e+01, ..., 2.1000e+01, 3.9690e+02,\n",
      "        7.8800e+00]]), 'target': array([24. , 21.6, 34.7, 33.4, 36.2, 28.7, 22.9, 27.1, 16.5, 18.9, 15. ,\n",
      "       18.9, 21.7, 20.4, 18.2, 19.9, 23.1, 17.5, 20.2, 18.2, 13.6, 19.6,\n",
      "       15.2, 14.5, 15.6, 13.9, 16.6, 14.8, 18.4, 21. , 12.7, 14.5, 13.2,\n",
      "       13.1, 13.5, 18.9, 20. , 21. , 24.7, 30.8, 34.9, 26.6, 25.3, 24.7,\n",
      "       21.2, 19.3, 20. , 16.6, 14.4, 19.4, 19.7, 20.5, 25. , 23.4, 18.9,\n",
      "       35.4, 24.7, 31.6, 23.3, 19.6, 18.7, 16. , 22.2, 25. , 33. , 23.5,\n",
      "       19.4, 22. , 17.4, 20.9, 24.2, 21.7, 22.8, 23.4, 24.1, 21.4, 20. ,\n",
      "       20.8, 21.2, 20.3, 28. , 23.9, 24.8, 22.9, 23.9, 26.6, 22.5, 22.2,\n",
      "       23.6, 28.7, 22.6, 22. , 22.9, 25. , 20.6, 28.4, 21.4, 38.7, 43.8,\n",
      "       33.2, 27.5, 26.5, 18.6, 19.3, 20.1, 19.5, 19.5, 20.4, 19.8, 19.4,\n",
      "       21.7, 22.8, 18.8, 18.7, 18.5, 18.3, 21.2, 19.2, 20.4, 19.3, 22. ,\n",
      "       20.3, 20.5, 17.3, 18.8, 21.4, 15.7, 16.2, 18. , 14.3, 19.2, 19.6,\n",
      "       23. , 18.4, 15.6, 18.1, 17.4, 17.1, 13.3, 17.8, 14. , 14.4, 13.4,\n",
      "       15.6, 11.8, 13.8, 15.6, 14.6, 17.8, 15.4, 21.5, 19.6, 15.3, 19.4,\n",
      "       17. , 15.6, 13.1, 41.3, 24.3, 23.3, 27. , 50. , 50. , 50. , 22.7,\n",
      "       25. , 50. , 23.8, 23.8, 22.3, 17.4, 19.1, 23.1, 23.6, 22.6, 29.4,\n",
      "       23.2, 24.6, 29.9, 37.2, 39.8, 36.2, 37.9, 32.5, 26.4, 29.6, 50. ,\n",
      "       32. , 29.8, 34.9, 37. , 30.5, 36.4, 31.1, 29.1, 50. , 33.3, 30.3,\n",
      "       34.6, 34.9, 32.9, 24.1, 42.3, 48.5, 50. , 22.6, 24.4, 22.5, 24.4,\n",
      "       20. , 21.7, 19.3, 22.4, 28.1, 23.7, 25. , 23.3, 28.7, 21.5, 23. ,\n",
      "       26.7, 21.7, 27.5, 30.1, 44.8, 50. , 37.6, 31.6, 46.7, 31.5, 24.3,\n",
      "       31.7, 41.7, 48.3, 29. , 24. , 25.1, 31.5, 23.7, 23.3, 22. , 20.1,\n",
      "       22.2, 23.7, 17.6, 18.5, 24.3, 20.5, 24.5, 26.2, 24.4, 24.8, 29.6,\n",
      "       42.8, 21.9, 20.9, 44. , 50. , 36. , 30.1, 33.8, 43.1, 48.8, 31. ,\n",
      "       36.5, 22.8, 30.7, 50. , 43.5, 20.7, 21.1, 25.2, 24.4, 35.2, 32.4,\n",
      "       32. , 33.2, 33.1, 29.1, 35.1, 45.4, 35.4, 46. , 50. , 32.2, 22. ,\n",
      "       20.1, 23.2, 22.3, 24.8, 28.5, 37.3, 27.9, 23.9, 21.7, 28.6, 27.1,\n",
      "       20.3, 22.5, 29. , 24.8, 22. , 26.4, 33.1, 36.1, 28.4, 33.4, 28.2,\n",
      "       22.8, 20.3, 16.1, 22.1, 19.4, 21.6, 23.8, 16.2, 17.8, 19.8, 23.1,\n",
      "       21. , 23.8, 23.1, 20.4, 18.5, 25. , 24.6, 23. , 22.2, 19.3, 22.6,\n",
      "       19.8, 17.1, 19.4, 22.2, 20.7, 21.1, 19.5, 18.5, 20.6, 19. , 18.7,\n",
      "       32.7, 16.5, 23.9, 31.2, 17.5, 17.2, 23.1, 24.5, 26.6, 22.9, 24.1,\n",
      "       18.6, 30.1, 18.2, 20.6, 17.8, 21.7, 22.7, 22.6, 25. , 19.9, 20.8,\n",
      "       16.8, 21.9, 27.5, 21.9, 23.1, 50. , 50. , 50. , 50. , 50. , 13.8,\n",
      "       13.8, 15. , 13.9, 13.3, 13.1, 10.2, 10.4, 10.9, 11.3, 12.3,  8.8,\n",
      "        7.2, 10.5,  7.4, 10.2, 11.5, 15.1, 23.2,  9.7, 13.8, 12.7, 13.1,\n",
      "       12.5,  8.5,  5. ,  6.3,  5.6,  7.2, 12.1,  8.3,  8.5,  5. , 11.9,\n",
      "       27.9, 17.2, 27.5, 15. , 17.2, 17.9, 16.3,  7. ,  7.2,  7.5, 10.4,\n",
      "        8.8,  8.4, 16.7, 14.2, 20.8, 13.4, 11.7,  8.3, 10.2, 10.9, 11. ,\n",
      "        9.5, 14.5, 14.1, 16.1, 14.3, 11.7, 13.4,  9.6,  8.7,  8.4, 12.8,\n",
      "       10.5, 17.1, 18.4, 15.4, 10.8, 11.8, 14.9, 12.6, 14.1, 13. , 13.4,\n",
      "       15.2, 16.1, 17.8, 14.9, 14.1, 12.7, 13.5, 14.9, 20. , 16.4, 17.7,\n",
      "       19.5, 20.2, 21.4, 19.9, 19. , 19.1, 19.1, 20.1, 19.9, 19.6, 23.2,\n",
      "       29.8, 13.8, 13.3, 16.7, 12. , 14.6, 21.4, 23. , 23.7, 25. , 21.8,\n",
      "       20.6, 21.2, 19.1, 20.6, 15.2,  7. ,  8.1, 13.6, 20.1, 21.8, 24.5,\n",
      "       23.1, 19.7, 18.3, 21.2, 17.5, 16.8, 22.4, 20.6, 23.9, 22. , 11.9]), 'feature_names': array(['CRIM', 'ZN', 'INDUS', 'CHAS', 'NOX', 'RM', 'AGE', 'DIS', 'RAD',\n",
      "       'TAX', 'PTRATIO', 'B', 'LSTAT'], dtype='<U7'), 'DESCR': \".. _boston_dataset:\\n\\nBoston house prices dataset\\n---------------------------\\n\\n**Data Set Characteristics:**  \\n\\n    :Number of Instances: 506 \\n\\n    :Number of Attributes: 13 numeric/categorical predictive. Median Value (attribute 14) is usually the target.\\n\\n    :Attribute Information (in order):\\n        - CRIM     per capita crime rate by town\\n        - ZN       proportion of residential land zoned for lots over 25,000 sq.ft.\\n        - INDUS    proportion of non-retail business acres per town\\n        - CHAS     Charles River dummy variable (= 1 if tract bounds river; 0 otherwise)\\n        - NOX      nitric oxides concentration (parts per 10 million)\\n        - RM       average number of rooms per dwelling\\n        - AGE      proportion of owner-occupied units built prior to 1940\\n        - DIS      weighted distances to five Boston employment centres\\n        - RAD      index of accessibility to radial highways\\n        - TAX      full-value property-tax rate per $10,000\\n        - PTRATIO  pupil-teacher ratio by town\\n        - B        1000(Bk - 0.63)^2 where Bk is the proportion of black people by town\\n        - LSTAT    % lower status of the population\\n        - MEDV     Median value of owner-occupied homes in $1000's\\n\\n    :Missing Attribute Values: None\\n\\n    :Creator: Harrison, D. and Rubinfeld, D.L.\\n\\nThis is a copy of UCI ML housing dataset.\\nhttps://archive.ics.uci.edu/ml/machine-learning-databases/housing/\\n\\n\\nThis dataset was taken from the StatLib library which is maintained at Carnegie Mellon University.\\n\\nThe Boston house-price data of Harrison, D. and Rubinfeld, D.L. 'Hedonic\\nprices and the demand for clean air', J. Environ. Economics & Management,\\nvol.5, 81-102, 1978.   Used in Belsley, Kuh & Welsch, 'Regression diagnostics\\n...', Wiley, 1980.   N.B. Various transformations are used in the table on\\npages 244-261 of the latter.\\n\\nThe Boston house-price data has been used in many machine learning papers that address regression\\nproblems.   \\n     \\n.. topic:: References\\n\\n   - Belsley, Kuh & Welsch, 'Regression diagnostics: Identifying Influential Data and Sources of Collinearity', Wiley, 1980. 244-261.\\n   - Quinlan,R. (1993). Combining Instance-Based and Model-Based Learning. In Proceedings on the Tenth International Conference of Machine Learning, 236-243, University of Massachusetts, Amherst. Morgan Kaufmann.\\n\", 'filename': 'C:\\\\Users\\\\Hp\\\\anaconda3\\\\lib\\\\site-packages\\\\sklearn\\\\datasets\\\\data\\\\boston_house_prices.csv'}\n"
     ]
    }
   ],
   "source": [
    "#Loading boston datset from sklearn library\n",
    "from sklearn.model_selection import train_test_split #library to split test and train dataset\n",
    "from sklearn.datasets import load_boston\n",
    "boston = load_boston()\n",
    "print(boston)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "fe9ad446",
   "metadata": {},
   "outputs": [],
   "source": [
    "#tranform data set into data frame\n",
    "df_x = pd.DataFrame(boston.data, columns=boston.feature_names)\n",
    "df_y = pd.DataFrame(boston.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "d7028efa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "354\n",
      "152\n",
      "354\n",
      "152\n",
      "118.0\n",
      "118.0\n"
     ]
    }
   ],
   "source": [
    "#splitting data 70% to 30%\n",
    "x_train, x_test, y_train, y_test = train_test_split(df_x, df_y, test_size=0.3, random_state=42)\n",
    "print(len(x_train))\n",
    "print(len(x_test))\n",
    "\n",
    "print(len(y_train))\n",
    "print(len(y_test))\n",
    "\n",
    "#making batches for training set, batches->3\n",
    "mBatch1 = []\n",
    "mBatch2 = []\n",
    "mBatch3 = []\n",
    "\n",
    "#assigning instances to batches\n",
    "mCalcl = int(len(x_train)/3)\n",
    "print(len(x_train)/3)\n",
    "for b in range(0, len(x_train)):\n",
    "    if b in range(0, mCalcl):\n",
    "        mBatch1.append(x_train.iloc[b].to_numpy())\n",
    "    if b in range(mCalcl, mCalcl*2):\n",
    "        mBatch2.append(x_train.iloc[b].to_numpy())\n",
    "    if b in range(mCalcl*2, mCalcl*3):\n",
    "        mBatch3.append(x_train.iloc[b].to_numpy())\n",
    "        \n",
    "        \n",
    "#making batches for testing set, batches->3       \n",
    "tmBatch1 = []\n",
    "tmBatch2 = []\n",
    "tmBatch3 = []\n",
    "\n",
    "#assigning instances to batches\n",
    "tmCalcl = int(len(x_test)/3)\n",
    "print(len(x_train)/3)\n",
    "for b in range(0, len(x_test)):\n",
    "    if b in range(0, tmCalcl):\n",
    "        tmBatch1.append(x_test.iloc[b].to_numpy())\n",
    "    if b in range(tmCalcl, tmCalcl*2):\n",
    "        tmBatch2.append(x_test.iloc[b].to_numpy())\n",
    "    if b in range(tmCalcl*2, tmCalcl*3):\n",
    "        tmBatch3.append(x_test.iloc[b].to_numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "718cbe35",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dot production function to multiply weights with inputs and thn add bias\n",
    "def dotProduct(inputs, weights, bias):\n",
    "    x = np.dot(inputs, np.array(weights).T) + biases\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "62bde23d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#activation function to activate per neuron\n",
    "def activation(hout):\n",
    "    for i in range(len(hout)):\n",
    "        hout[i] = np.maximum(0.0, hout[i])\n",
    "    return hout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "a79c256c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Error function to calculate error per instance\n",
    "Error = []\n",
    "def error(target, foutput):\n",
    "    global Error\n",
    "    Error.append(pow(target - foutput,2))\n",
    "    avg = sum(Error)/len(Error)\n",
    "    return avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "71b57b6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  1\n",
      "Averager error/loss in first epoch =  [10814.69070543]\n",
      "Epoch  2\n",
      "Averager error/loss in first epoch =  [10811.01757029]\n",
      "Epoch  3\n",
      "Averager error/loss in first epoch =  [10807.38062367]\n",
      "Epoch  4\n",
      "Averager error/loss in first epoch =  [10803.77933339]\n",
      "Epoch  5\n",
      "Averager error/loss in first epoch =  [10800.21317765]\n",
      "Epoch  6\n",
      "Averager error/loss in first epoch =  [10796.68164479]\n",
      "Epoch  7\n",
      "Averager error/loss in first epoch =  [10793.18423301]\n",
      "Epoch  8\n",
      "Averager error/loss in first epoch =  [10789.72045019]\n",
      "Epoch  9\n",
      "Averager error/loss in first epoch =  [10786.28981363]\n",
      "Epoch  10\n",
      "Averager error/loss in first epoch =  [10782.89184978]\n",
      "Epoch  11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Hp\\AppData\\Local\\Temp/ipykernel_17688/281222677.py:2: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  x = np.dot(inputs, np.array(weights).T) + biases\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Averager error/loss in first epoch =  [10779.52609413]\n",
      "Epoch  12\n",
      "Averager error/loss in first epoch =  [10776.19209089]\n",
      "Epoch  13\n",
      "Averager error/loss in first epoch =  [10772.88939285]\n",
      "Epoch  14\n",
      "Averager error/loss in first epoch =  [10769.61756114]\n",
      "Epoch  15\n",
      "Averager error/loss in first epoch =  [10766.37616507]\n",
      "Epoch  16\n",
      "Averager error/loss in first epoch =  [10763.16478193]\n",
      "Epoch  17\n",
      "Averager error/loss in first epoch =  [10759.98299679]\n",
      "Epoch  18\n",
      "Averager error/loss in first epoch =  [10756.83040235]\n",
      "Epoch  19\n",
      "Averager error/loss in first epoch =  [10753.70659872]\n",
      "Epoch  20\n",
      "Averager error/loss in first epoch =  [10750.6111933]\n",
      "Epoch  21\n",
      "Averager error/loss in first epoch =  [10747.5438006]\n",
      "Epoch  22\n",
      "Averager error/loss in first epoch =  [10744.50404207]\n",
      "Epoch  23\n",
      "Averager error/loss in first epoch =  [10741.49154595]\n",
      "Epoch  24\n",
      "Averager error/loss in first epoch =  [10738.50594712]\n",
      "Epoch  25\n",
      "Averager error/loss in first epoch =  [10735.54688694]\n",
      "Epoch  26\n",
      "Averager error/loss in first epoch =  [10732.61401313]\n",
      "Epoch  27\n",
      "Averager error/loss in first epoch =  [10729.70697963]\n",
      "Epoch  28\n",
      "Averager error/loss in first epoch =  [10726.82544642]\n",
      "Epoch  29\n",
      "Averager error/loss in first epoch =  [10723.96907943]\n",
      "Epoch  30\n",
      "Averager error/loss in first epoch =  [10721.13755042]\n",
      "Epoch  31\n",
      "Averager error/loss in first epoch =  [10718.33053681]\n",
      "Epoch  32\n",
      "Averager error/loss in first epoch =  [10715.5477216]\n",
      "Epoch  33\n",
      "Averager error/loss in first epoch =  [10712.78879321]\n",
      "Epoch  34\n",
      "Averager error/loss in first epoch =  [10710.05344541]\n",
      "Epoch  35\n",
      "Averager error/loss in first epoch =  [10707.34137716]\n",
      "Epoch  36\n",
      "Averager error/loss in first epoch =  [10704.65229254]\n",
      "Epoch  37\n",
      "Averager error/loss in first epoch =  [10701.98590062]\n",
      "Epoch  38\n",
      "Averager error/loss in first epoch =  [10699.34191535]\n",
      "Epoch  39\n",
      "Averager error/loss in first epoch =  [10696.72005548]\n",
      "Epoch  40\n",
      "Averager error/loss in first epoch =  [10694.12004445]\n",
      "Epoch  41\n",
      "Averager error/loss in first epoch =  [10691.54161027]\n",
      "Epoch  42\n",
      "Averager error/loss in first epoch =  [10688.98448546]\n",
      "Epoch  43\n",
      "Averager error/loss in first epoch =  [10686.44840695]\n",
      "Epoch  44\n",
      "Averager error/loss in first epoch =  [10683.93311597]\n",
      "Epoch  45\n",
      "Averager error/loss in first epoch =  [10681.43835797]\n",
      "Epoch  46\n",
      "Averager error/loss in first epoch =  [10678.96388256]\n",
      "Epoch  47\n",
      "Averager error/loss in first epoch =  [10676.50944339]\n",
      "Epoch  48\n",
      "Averager error/loss in first epoch =  [10674.07479808]\n",
      "Epoch  49\n",
      "Averager error/loss in first epoch =  [10671.65970816]\n",
      "Epoch  50\n",
      "Averager error/loss in first epoch =  [10669.26393896]\n",
      "Epoch  51\n",
      "Averager error/loss in first epoch =  [10666.88725955]\n",
      "Epoch  52\n",
      "Averager error/loss in first epoch =  [10664.52944267]\n",
      "Epoch  53\n",
      "Averager error/loss in first epoch =  [10662.19026467]\n",
      "Epoch  54\n",
      "Averager error/loss in first epoch =  [10659.86950538]\n",
      "Epoch  55\n",
      "Averager error/loss in first epoch =  [10657.56694814]\n",
      "Epoch  56\n",
      "Averager error/loss in first epoch =  [10655.28237962]\n",
      "Epoch  57\n",
      "Averager error/loss in first epoch =  [10653.01558984]\n",
      "Epoch  58\n",
      "Averager error/loss in first epoch =  [10650.76637208]\n",
      "Epoch  59\n",
      "Averager error/loss in first epoch =  [10648.53452279]\n",
      "Epoch  60\n",
      "Averager error/loss in first epoch =  [10646.31984158]\n",
      "Epoch  61\n",
      "Averager error/loss in first epoch =  [10644.1221311]\n",
      "Epoch  62\n",
      "Averager error/loss in first epoch =  [10641.94119704]\n",
      "Epoch  63\n",
      "Averager error/loss in first epoch =  [10639.77684803]\n",
      "Epoch  64\n",
      "Averager error/loss in first epoch =  [10637.6288956]\n",
      "Epoch  65\n",
      "Averager error/loss in first epoch =  [10635.49715413]\n",
      "Epoch  66\n",
      "Averager error/loss in first epoch =  [10633.3814408]\n",
      "Epoch  67\n",
      "Averager error/loss in first epoch =  [10631.28157551]\n",
      "Epoch  68\n",
      "Averager error/loss in first epoch =  [10629.19738085]\n",
      "Epoch  69\n",
      "Averager error/loss in first epoch =  [10627.12868206]\n",
      "Epoch  70\n",
      "Averager error/loss in first epoch =  [10625.07530697]\n",
      "Epoch  71\n",
      "Averager error/loss in first epoch =  [10623.03708593]\n",
      "Epoch  72\n",
      "Averager error/loss in first epoch =  [10621.01385182]\n",
      "Epoch  73\n",
      "Averager error/loss in first epoch =  [10619.00543994]\n",
      "Epoch  74\n",
      "Averager error/loss in first epoch =  [10617.01168799]\n",
      "Epoch  75\n",
      "Averager error/loss in first epoch =  [10615.03243606]\n",
      "Epoch  76\n",
      "Averager error/loss in first epoch =  [10613.06752654]\n",
      "Epoch  77\n",
      "Averager error/loss in first epoch =  [10611.11680408]\n",
      "Epoch  78\n",
      "Averager error/loss in first epoch =  [10609.1801156]\n",
      "Epoch  79\n",
      "Averager error/loss in first epoch =  [10607.2573102]\n",
      "Epoch  80\n",
      "Averager error/loss in first epoch =  [10605.34823912]\n",
      "Epoch  81\n",
      "Averager error/loss in first epoch =  [10603.45275573]\n",
      "Epoch  82\n",
      "Averager error/loss in first epoch =  [10601.57071548]\n",
      "Epoch  83\n",
      "Averager error/loss in first epoch =  [10599.70197588]\n",
      "Epoch  84\n",
      "Averager error/loss in first epoch =  [10597.84639641]\n",
      "Epoch  85\n",
      "Averager error/loss in first epoch =  [10596.00383855]\n",
      "Epoch  86\n",
      "Averager error/loss in first epoch =  [10594.17416572]\n",
      "Epoch  87\n",
      "Averager error/loss in first epoch =  [10592.35724321]\n",
      "Epoch  88\n",
      "Averager error/loss in first epoch =  [10590.55293823]\n",
      "Epoch  89\n",
      "Averager error/loss in first epoch =  [10588.76111978]\n",
      "Epoch  90\n",
      "Averager error/loss in first epoch =  [10586.9816587]\n",
      "Epoch  91\n",
      "Averager error/loss in first epoch =  [10585.2144276]\n",
      "Epoch  92\n",
      "Averager error/loss in first epoch =  [10583.45930081]\n",
      "Epoch  93\n",
      "Averager error/loss in first epoch =  [10581.71615442]\n",
      "Epoch  94\n",
      "Averager error/loss in first epoch =  [10579.98486616]\n",
      "Epoch  95\n",
      "Averager error/loss in first epoch =  [10578.26531545]\n",
      "Epoch  96\n",
      "Averager error/loss in first epoch =  [10576.55738333]\n",
      "Epoch  97\n",
      "Averager error/loss in first epoch =  [10574.86095243]\n",
      "Epoch  98\n",
      "Averager error/loss in first epoch =  [10573.17590698]\n",
      "Epoch  99\n",
      "Averager error/loss in first epoch =  [10571.50213273]\n",
      "Epoch  100\n",
      "Averager error/loss in first epoch =  [10569.83951698]\n"
     ]
    }
   ],
   "source": [
    "#back up\n",
    "x0 = .15\n",
    "x1 = 0.20\n",
    "x2 = .21\n",
    "x3 = .12\n",
    "x4 = .21\n",
    "x5 = .15\n",
    "x6 = 0.20\n",
    "x7 = .05\n",
    "x8 = .087\n",
    "x9 = .04\n",
    "x10 = .9\n",
    "x11 = .07\n",
    "x12 = .008\n",
    "\n",
    "x13 = .25\n",
    "x14 = .30\n",
    "x15 = .04\n",
    "x16 = .9\n",
    "x17 = .07\n",
    "x18 = .008\n",
    "x19 = .0043\n",
    "x20 = .025\n",
    "x21 = .001\n",
    "x22 = .078\n",
    "x23 = 0.25\n",
    "x24 = .98\n",
    "x25 = .5\n",
    "\n",
    "xx1 = .25\n",
    "xx2 = .45\n",
    "\n",
    "Epoch = 10\n",
    "er = 0\n",
    "AverageError = []\n",
    "global mBatch1\n",
    "global mBatch2\n",
    "global mBatch3\n",
    "n = 0.3\n",
    "for e in range(0, 100):\n",
    "    global AverageError\n",
    "    global Error\n",
    "    global er\n",
    "    print(\"Epoch \", e+1)\n",
    "    for j in range(0, len(mBatch1)):\n",
    "        inputs = mBatch1[j]\n",
    "        weights = [[x0, x1, x2, x3, x4, x5, x6, x7, x8, x9, x10, x11, x12], [x13, x14, x15, x16, x17, x18, x19, x20, x21, x22, x23, x24, x25]]\n",
    "        biases = [.35]\n",
    "        out = dotProduct(inputs, weights, biases)\n",
    "        \n",
    "        hout = activation(out)\n",
    "        input2 = hout\n",
    "        weight2 = [xx1, xx2]\n",
    "        bias2 = [.21]\n",
    "\n",
    "        finalOutput = dotProduct(input2, weight2, bias2) \n",
    "\n",
    "        #relu functiona\n",
    "        foutput = activation(finalOutput)\n",
    "        \n",
    "        if j == (len(mBatch1)-1):\n",
    "            er = error(y_train.iloc[j].to_numpy(), foutput)\n",
    "    \n",
    "            #To backpropogate, inorder to update weights\n",
    "            for i in range(0, 28):\n",
    "                x = 0.0\n",
    "                if i == 26:\n",
    "                    weight2[0] = -(y_train.iloc[i].to_numpy() - foutput) * (foutput * (1-foutput)) * weight2[0]\n",
    "                    weight2[0] = weight2[0] + weight2[0] + ((-n) * (weight2[0]))\n",
    "                if i == 27:\n",
    "                    weight2[1] = -(y_train.iloc[i].to_numpy() - foutput) * (foutput * (1-foutput)) * weight2[1]\n",
    "                    weight2[0] = weight2[0] + ((-n) * (weight2[0]))\n",
    "                if i in range(0, 13, 1):\n",
    "                    weights[0][i] = -(-(y_train.iloc[i].to_numpy() - foutput) * (foutput * (1 - foutput)) * weight2[0] * (hout[0] * (1 - hout[0])) * inputs[i])\n",
    "                    weights[0][i] = weights[0][i] + ((-n) * (weights[0][i]))\n",
    "                    if i == 0:\n",
    "                        x0 = weights[0][i]\n",
    "                    elif i == 1:\n",
    "                        x1 = weights[0][i]\n",
    "                    elif i == 2:\n",
    "                        x2 = weights[0][i]\n",
    "                    elif i == 3:\n",
    "                        x3 = weights[0][i]\n",
    "                    elif i == 4:\n",
    "                        x4 = weights[0][i]\n",
    "                    elif i == 5:\n",
    "                        x5 = weights[0][i]\n",
    "                    elif i == 6:\n",
    "                        x6 = weights[0][i]\n",
    "                    elif i == 7:\n",
    "                        x7 = weights[0][i]\n",
    "                    elif i == 8:\n",
    "                        x8 = weights[0][i]\n",
    "                    elif i == 9:\n",
    "                        x9 = weights[0][i]\n",
    "                    elif i == 10:\n",
    "                        x10 = weights[0][i]\n",
    "                    elif i == 11:\n",
    "                        x12 = weights[0][i]\n",
    "                    elif i == 12:\n",
    "                        x12 = weights[0][i]\n",
    "\n",
    "                if i in range(13, 26, 1):\n",
    "                    weights[1][i%13] = -(-(y_train.iloc[i].to_numpy() - foutput) * (foutput * (1 - foutput)) * weight2[1] * (hout[1] * (1 - hout[1])) * inputs[i%13])\n",
    "                    weights[1][i%13] = weights[1][i%13] + ((-n) * (weights[1][i%13]))\n",
    "                    if i == 13:\n",
    "                        x13 = weights[1][i%13]\n",
    "                    elif i == 14:\n",
    "                        x14 = weights[1][i%13]\n",
    "                    elif i == 15:\n",
    "                        x15 = weights[1][i%13]\n",
    "                    elif i == 16:\n",
    "                        x16 = weights[1][i%13]\n",
    "                    elif i == 17:\n",
    "                        x17 = weights[1][i%13]\n",
    "                    elif i == 18:\n",
    "                        x18 = weights[1][i%13]\n",
    "                    elif i == 19:\n",
    "                        x19 = weights[1][i%13]\n",
    "                    elif i == 20:\n",
    "                        x20 = weights[1][i%13]\n",
    "                    elif i == 21:\n",
    "                        x21 = weights[1][i%13]\n",
    "                    elif i == 22:\n",
    "                        x22 = weights[1][i%13]\n",
    "                    elif i == 23:\n",
    "                        x23 = weights[1][i%13]\n",
    "                    elif i == 24:\n",
    "                        x24 = weights[1][i%13]\n",
    "                    elif i == 25:\n",
    "                        x25 = weights[1][i%13]\n",
    "\n",
    "\n",
    "    for j in range(0, len(mBatch2)):\n",
    "        inputs = mBatch2[j]\n",
    "        weights = [[.15, 0.20, .21, .12, .21, .15, 0.20, .05, .087, .04, .9, .07, .008], [.25, .30, .04, .9, .07, .008, .0043, .025, .001, .078, 0.25, .98, .5]]\n",
    "        biases = [.35]\n",
    "        out = dotProduct(inputs, weights, biases)\n",
    "        \n",
    "        hout = activation(out)\n",
    "        input2 = hout\n",
    "        weight2 = [.25, .45]\n",
    "        bias2 = [.21]\n",
    "\n",
    "        finalOutput = dotProduct(input2, weight2, bias2) \n",
    "\n",
    "        #relu functiona\n",
    "        foutput = activation(finalOutput)\n",
    "        \n",
    "        if j == (len(mBatch2)-1):\n",
    "            er = error(y_train.iloc[j].to_numpy(), foutput)\n",
    "            \n",
    "            #To backpropogate, inorder to update weights\n",
    "            for i in range(0, 28):\n",
    "                x = 0.0\n",
    "                if i == 26:\n",
    "                    weight2[0] = -(y_train.iloc[i].to_numpy() - foutput) * (foutput * (1-foutput)) * weight2[0]\n",
    "                    weight2[0] = weight2[0] + weight2[0] + ((-n) * (weight2[0]))\n",
    "                if i == 27:\n",
    "                    weight2[1] = -(y_train.iloc[i].to_numpy() - foutput) * (foutput * (1-foutput)) * weight2[1]\n",
    "                    weight2[0] = weight2[0] + ((-n) * (weight2[0]))\n",
    "                if i in range(0, 13, 1):\n",
    "                    weights[0][i] = -(-(y_train.iloc[i].to_numpy() - foutput) * (foutput * (1 - foutput)) * weight2[0] * (hout[0] * (1 - hout[0])) * inputs[i])\n",
    "                    weights[0][i] = weights[0][i] + ((-n) * (weights[0][i]))\n",
    "                    if i == 0:\n",
    "                        x0 = weights[0][i]\n",
    "                    elif i == 1:\n",
    "                        x1 = weights[0][i]\n",
    "                    elif i == 2:\n",
    "                        x2 = weights[0][i]\n",
    "                    elif i == 3:\n",
    "                        x3 = weights[0][i]\n",
    "                    elif i == 4:\n",
    "                        x4 = weights[0][i]\n",
    "                    elif i == 5:\n",
    "                        x5 = weights[0][i]\n",
    "                    elif i == 6:\n",
    "                        x6 = weights[0][i]\n",
    "                    elif i == 7:\n",
    "                        x7 = weights[0][i]\n",
    "                    elif i == 8:\n",
    "                        x8 = weights[0][i]\n",
    "                    elif i == 9:\n",
    "                        x9 = weights[0][i]\n",
    "                    elif i == 10:\n",
    "                        x10 = weights[0][i]\n",
    "                    elif i == 11:\n",
    "                        x12 = weights[0][i]\n",
    "                    elif i == 12:\n",
    "                        x12 = weights[0][i]\n",
    "\n",
    "                if i in range(13, 26, 1):\n",
    "                    weights[1][i%13] = -(-(y_train.iloc[i].to_numpy() - foutput) * (foutput * (1 - foutput)) * weight2[1] * (hout[1] * (1 - hout[1])) * inputs[i%13])\n",
    "                    weights[1][i%13] = weights[1][i%13] + ((-n) * (weights[1][i%13]))\n",
    "                    if i == 13:\n",
    "                        x13 = weights[1][i%13]\n",
    "                    elif i == 14:\n",
    "                        x14 = weights[1][i%13]\n",
    "                    elif i == 15:\n",
    "                        x15 = weights[1][i%13]\n",
    "                    elif i == 16:\n",
    "                        x16 = weights[1][i%13]\n",
    "                    elif i == 17:\n",
    "                        x17 = weights[1][i%13]\n",
    "                    elif i == 18:\n",
    "                        x18 = weights[1][i%13]\n",
    "                    elif i == 19:\n",
    "                        x19 = weights[1][i%13]\n",
    "                    elif i == 20:\n",
    "                        x20 = weights[1][i%13]\n",
    "                    elif i == 21:\n",
    "                        x21 = weights[1][i%13]\n",
    "                    elif i == 22:\n",
    "                        x22 = weights[1][i%13]\n",
    "                    elif i == 23:\n",
    "                        x23 = weights[1][i%13]\n",
    "                    elif i == 24:\n",
    "                        x24 = weights[1][i%13]\n",
    "                    elif i == 25:\n",
    "                        x25 = weights[1][i%13]\n",
    "\n",
    "    for j in range(0, len(mBatch3)):\n",
    "        inputs = mBatch3[j]\n",
    "        weights = [[.15, 0.20, .21, .12, .21, .15, 0.20, .05, .087, .04, .9, .07, .008], [.25, .30, .04, .9, .07, .008, .0043, .025, .001, .078, 0.25, .98, .5]]\n",
    "        biases = [.35]\n",
    "        out = dotProduct(inputs, weights, biases)\n",
    "\n",
    "        hout = activation(out)\n",
    "        input2 = hout\n",
    "        weight2 = [.25, .45]\n",
    "        bias2 = [.21]\n",
    "\n",
    "        finalOutput = dotProduct(input2, weight2, bias2) \n",
    "\n",
    "        #relu functiona\n",
    "        foutput = activation(finalOutput)\n",
    "\n",
    "    if j == (len(mBatch2)-1):\n",
    "        er = error(y_train.iloc[j].to_numpy(), foutput)\n",
    "        \n",
    "        #To backpropogate, inorder to update weights\n",
    "        for i in range(0, 28):\n",
    "            x = 0.0\n",
    "            if i == 26:\n",
    "                weight2[0] = -(y_train.iloc[i].to_numpy() - foutput) * (foutput * (1-foutput)) * weight2[0]\n",
    "                weight2[0] = weight2[0] + weight2[0] + ((-n) * (weight2[0]))\n",
    "            if i == 27:\n",
    "                weight2[1] = -(y_train.iloc[i].to_numpy() - foutput) * (foutput * (1-foutput)) * weight2[1]\n",
    "                weight2[0] = weight2[0] + ((-n) * (weight2[0]))\n",
    "            if i in range(0, 13, 1):\n",
    "                weights[0][i] = -(-(y_train.iloc[i].to_numpy() - foutput) * (foutput * (1 - foutput)) * weight2[0] * (hout[0] * (1 - hout[0])) * inputs[i])\n",
    "                weights[0][i] = weights[0][i] + ((-n) * (weights[0][i]))\n",
    "                if i == 0:\n",
    "                    x0 = weights[0][i]\n",
    "                elif i == 1:\n",
    "                    x1 = weights[0][i]\n",
    "                elif i == 2:\n",
    "                    x2 = weights[0][i]\n",
    "                elif i == 3:\n",
    "                    x3 = weights[0][i]\n",
    "                elif i == 4:\n",
    "                    x4 = weights[0][i]\n",
    "                elif i == 5:\n",
    "                    x5 = weights[0][i]\n",
    "                elif i == 6:\n",
    "                    x6 = weights[0][i]\n",
    "                elif i == 7:\n",
    "                    x7 = weights[0][i]\n",
    "                elif i == 8:\n",
    "                    x8 = weights[0][i]\n",
    "                elif i == 9:\n",
    "                    x9 = weights[0][i]\n",
    "                elif i == 10:\n",
    "                    x10 = weights[0][i]\n",
    "                elif i == 11:\n",
    "                    x12 = weights[0][i]\n",
    "                elif i == 12:\n",
    "                    x12 = weights[0][i]\n",
    "\n",
    "            if i in range(13, 26, 1):\n",
    "                weights[1][i%13] = -(-(y_train.iloc[i].to_numpy() - foutput) * (foutput * (1 - foutput)) * weight2[1] * (hout[1] * (1 - hout[1])) * inputs[i%13])\n",
    "                weights[1][i%13] = weights[1][i%13] + ((-n) * (weights[1][i%13]))\n",
    "                if i == 13:\n",
    "                    x13 = weights[1][i%13]\n",
    "                elif i == 14:\n",
    "                    x14 = weights[1][i%13]\n",
    "                elif i == 15:\n",
    "                    x15 = weights[1][i%13]\n",
    "                elif i == 16:\n",
    "                    x16 = weights[1][i%13]\n",
    "                elif i == 17:\n",
    "                    x17 = weights[1][i%13]\n",
    "                elif i == 18:\n",
    "                    x18 = weights[1][i%13]\n",
    "                elif i == 19:\n",
    "                    x19 = weights[1][i%13]\n",
    "                elif i == 20:\n",
    "                    x20 = weights[1][i%13]\n",
    "                elif i == 21:\n",
    "                    x21 = weights[1][i%13]\n",
    "                elif i == 22:\n",
    "                    x22 = weights[1][i%13]\n",
    "                elif i == 23:\n",
    "                    x23 = weights[1][i%13]\n",
    "                elif i == 24:\n",
    "                    x24 = weights[1][i%13]\n",
    "                elif i == 25:\n",
    "                    x25 = weights[1][i%13]\n",
    "\n",
    "    AverageError.append(er)\n",
    "    print(\"Averager error/loss in first epoch = \", AverageError[e])\n",
    "    er = 0\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "7c62e02d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  1\n",
      "Averager error/loss in first epoch =  [10775.32800542]\n",
      "Epoch  2\n",
      "Averager error/loss in first epoch =  [10776.84631847]\n",
      "Epoch  3\n",
      "Averager error/loss in first epoch =  [10778.35709647]\n",
      "Epoch  4\n",
      "Averager error/loss in first epoch =  [10779.86039537]\n",
      "Epoch  5\n",
      "Averager error/loss in first epoch =  [10781.35627057]\n",
      "Epoch  6\n",
      "Averager error/loss in first epoch =  [10782.84477693]\n",
      "Epoch  7\n",
      "Averager error/loss in first epoch =  [10784.32596876]\n",
      "Epoch  8\n",
      "Averager error/loss in first epoch =  [10785.79989985]\n",
      "Epoch  9\n",
      "Averager error/loss in first epoch =  [10787.26662345]\n",
      "Epoch  10\n",
      "Averager error/loss in first epoch =  [10788.7261923]\n",
      "Epoch  11\n",
      "Averager error/loss in first epoch =  [10790.17865863]\n",
      "Epoch  12\n",
      "Averager error/loss in first epoch =  [10791.62407415]\n",
      "Epoch  13\n",
      "Averager error/loss in first epoch =  [10793.06249007]\n",
      "Epoch  14\n",
      "Averager error/loss in first epoch =  [10794.49395713]\n",
      "Epoch  15\n",
      "Averager error/loss in first epoch =  [10795.91852556]\n",
      "Epoch  16\n",
      "Averager error/loss in first epoch =  [10797.33624509]\n",
      "Epoch  17\n",
      "Averager error/loss in first epoch =  [10798.74716501]\n",
      "Epoch  18\n",
      "Averager error/loss in first epoch =  [10800.15133412]\n",
      "Epoch  19\n",
      "Averager error/loss in first epoch =  [10801.54880075]\n",
      "Epoch  20\n",
      "Averager error/loss in first epoch =  [10802.93961278]\n",
      "Epoch  21\n",
      "Averager error/loss in first epoch =  [10804.32381762]\n",
      "Epoch  22\n",
      "Averager error/loss in first epoch =  [10805.70146225]\n",
      "Epoch  23\n",
      "Averager error/loss in first epoch =  [10807.0725932]\n",
      "Epoch  24\n",
      "Averager error/loss in first epoch =  [10808.43725655]\n",
      "Epoch  25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Hp\\AppData\\Local\\Temp/ipykernel_17688/281222677.py:2: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  x = np.dot(inputs, np.array(weights).T) + biases\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Averager error/loss in first epoch =  [10809.79549795]\n",
      "Epoch  26\n",
      "Averager error/loss in first epoch =  [10811.14736263]\n",
      "Epoch  27\n",
      "Averager error/loss in first epoch =  [10812.49289539]\n",
      "Epoch  28\n",
      "Averager error/loss in first epoch =  [10813.83214062]\n",
      "Epoch  29\n",
      "Averager error/loss in first epoch =  [10815.16514228]\n",
      "Epoch  30\n",
      "Averager error/loss in first epoch =  [10816.49194393]\n",
      "Epoch  31\n",
      "Averager error/loss in first epoch =  [10817.81258873]\n",
      "Epoch  32\n",
      "Averager error/loss in first epoch =  [10819.12711943]\n",
      "Epoch  33\n",
      "Averager error/loss in first epoch =  [10820.4355784]\n",
      "Epoch  34\n",
      "Averager error/loss in first epoch =  [10821.7380076]\n",
      "Epoch  35\n",
      "Averager error/loss in first epoch =  [10823.03444862]\n",
      "Epoch  36\n",
      "Averager error/loss in first epoch =  [10824.32494267]\n",
      "Epoch  37\n",
      "Averager error/loss in first epoch =  [10825.60953056]\n",
      "Epoch  38\n",
      "Averager error/loss in first epoch =  [10826.88825276]\n",
      "Epoch  39\n",
      "Averager error/loss in first epoch =  [10828.16114934]\n",
      "Epoch  40\n",
      "Averager error/loss in first epoch =  [10829.42826003]\n",
      "Epoch  41\n",
      "Averager error/loss in first epoch =  [10830.68962418]\n",
      "Epoch  42\n",
      "Averager error/loss in first epoch =  [10831.94528081]\n",
      "Epoch  43\n",
      "Averager error/loss in first epoch =  [10833.19526855]\n",
      "Epoch  44\n",
      "Averager error/loss in first epoch =  [10834.43962572]\n",
      "Epoch  45\n",
      "Averager error/loss in first epoch =  [10835.67839028]\n",
      "Epoch  46\n",
      "Averager error/loss in first epoch =  [10836.91159983]\n",
      "Epoch  47\n",
      "Averager error/loss in first epoch =  [10838.13929167]\n",
      "Epoch  48\n",
      "Averager error/loss in first epoch =  [10839.36150275]\n",
      "Epoch  49\n",
      "Averager error/loss in first epoch =  [10840.57826967]\n",
      "Epoch  50\n",
      "Averager error/loss in first epoch =  [10841.78962874]\n",
      "Epoch  51\n",
      "Averager error/loss in first epoch =  [10842.99561594]\n",
      "Epoch  52\n",
      "Averager error/loss in first epoch =  [10844.1962669]\n",
      "Epoch  53\n",
      "Averager error/loss in first epoch =  [10845.39161698]\n",
      "Epoch  54\n",
      "Averager error/loss in first epoch =  [10846.5817012]\n",
      "Epoch  55\n",
      "Averager error/loss in first epoch =  [10847.76655428]\n",
      "Epoch  56\n",
      "Averager error/loss in first epoch =  [10848.94621063]\n",
      "Epoch  57\n",
      "Averager error/loss in first epoch =  [10850.12070438]\n",
      "Epoch  58\n",
      "Averager error/loss in first epoch =  [10851.29006933]\n",
      "Epoch  59\n",
      "Averager error/loss in first epoch =  [10852.45433901]\n",
      "Epoch  60\n",
      "Averager error/loss in first epoch =  [10853.61354665]\n",
      "Epoch  61\n",
      "Averager error/loss in first epoch =  [10854.76772518]\n",
      "Epoch  62\n",
      "Averager error/loss in first epoch =  [10855.91690728]\n",
      "Epoch  63\n",
      "Averager error/loss in first epoch =  [10857.0611253]\n",
      "Epoch  64\n",
      "Averager error/loss in first epoch =  [10858.20041135]\n",
      "Epoch  65\n",
      "Averager error/loss in first epoch =  [10859.33479725]\n",
      "Epoch  66\n",
      "Averager error/loss in first epoch =  [10860.46431453]\n",
      "Epoch  67\n",
      "Averager error/loss in first epoch =  [10861.58899448]\n",
      "Epoch  68\n",
      "Averager error/loss in first epoch =  [10862.70886811]\n",
      "Epoch  69\n",
      "Averager error/loss in first epoch =  [10863.82396616]\n",
      "Epoch  70\n",
      "Averager error/loss in first epoch =  [10864.93431911]\n",
      "Epoch  71\n",
      "Averager error/loss in first epoch =  [10866.03995718]\n",
      "Epoch  72\n",
      "Averager error/loss in first epoch =  [10867.14091035]\n",
      "Epoch  73\n",
      "Averager error/loss in first epoch =  [10868.23720832]\n",
      "Epoch  74\n",
      "Averager error/loss in first epoch =  [10869.32888057]\n",
      "Epoch  75\n",
      "Averager error/loss in first epoch =  [10870.4159563]\n",
      "Epoch  76\n",
      "Averager error/loss in first epoch =  [10871.49846448]\n",
      "Epoch  77\n",
      "Averager error/loss in first epoch =  [10872.57643385]\n",
      "Epoch  78\n",
      "Averager error/loss in first epoch =  [10873.64989288]\n",
      "Epoch  79\n",
      "Averager error/loss in first epoch =  [10874.71886983]\n",
      "Epoch  80\n",
      "Averager error/loss in first epoch =  [10875.78339271]\n",
      "Epoch  81\n",
      "Averager error/loss in first epoch =  [10876.8434893]\n",
      "Epoch  82\n",
      "Averager error/loss in first epoch =  [10877.89918715]\n",
      "Epoch  83\n",
      "Averager error/loss in first epoch =  [10878.95051358]\n",
      "Epoch  84\n",
      "Averager error/loss in first epoch =  [10879.99749569]\n",
      "Epoch  85\n",
      "Averager error/loss in first epoch =  [10881.04016034]\n",
      "Epoch  86\n",
      "Averager error/loss in first epoch =  [10882.07853419]\n",
      "Epoch  87\n",
      "Averager error/loss in first epoch =  [10883.11264367]\n",
      "Epoch  88\n",
      "Averager error/loss in first epoch =  [10884.142515]\n",
      "Epoch  89\n",
      "Averager error/loss in first epoch =  [10885.16817418]\n",
      "Epoch  90\n",
      "Averager error/loss in first epoch =  [10886.18964699]\n",
      "Epoch  91\n",
      "Averager error/loss in first epoch =  [10887.20695902]\n",
      "Epoch  92\n",
      "Averager error/loss in first epoch =  [10888.22013563]\n",
      "Epoch  93\n",
      "Averager error/loss in first epoch =  [10889.22920199]\n",
      "Epoch  94\n",
      "Averager error/loss in first epoch =  [10890.23418307]\n",
      "Epoch  95\n",
      "Averager error/loss in first epoch =  [10891.23510361]\n",
      "Epoch  96\n",
      "Averager error/loss in first epoch =  [10892.23198818]\n",
      "Epoch  97\n",
      "Averager error/loss in first epoch =  [10893.22486115]\n",
      "Epoch  98\n",
      "Averager error/loss in first epoch =  [10894.21374667]\n",
      "Epoch  99\n",
      "Averager error/loss in first epoch =  [10895.19866873]\n",
      "Epoch  100\n",
      "Averager error/loss in first epoch =  [10896.1796511]\n"
     ]
    }
   ],
   "source": [
    "#Same operation as above cell but this time for testing data\n",
    "Epoch = 10\n",
    "ter = 0\n",
    "tAverageError = []\n",
    "global tmBatch1\n",
    "global tmBatch2\n",
    "global tmBatch3\n",
    "n = 0.3\n",
    "for e in range(0, 100):\n",
    "    global AverageError\n",
    "    global Error\n",
    "    global ter\n",
    "    print(\"Epoch \", e+1)\n",
    "    for j in range(0, len(tmBatch1)):\n",
    "        inputs = tmBatch1[j]\n",
    "        weights = [[x0, x1, x2, x3, x4, x5, x6, x7, x8, x9, x10, x11, x12], [x13, x14, x15, x16, x17, x18, x19, x20, x21, x22, x23, x24, x25]]\n",
    "        biases = [.35]\n",
    "        out = dotProduct(inputs, weights, biases)\n",
    "        \n",
    "        hout = activation(out)\n",
    "        input2 = hout\n",
    "        weight2 = [xx1, xx2]\n",
    "        bias2 = [.21]\n",
    "\n",
    "        finalOutput = dotProduct(input2, weight2, bias2) \n",
    "\n",
    "        #relu functiona\n",
    "        foutput = activation(finalOutput)\n",
    "        \n",
    "        if j == (len(tmBatch1)-1):\n",
    "            ter = error(y_test.iloc[j].to_numpy(), foutput)\n",
    "    \n",
    "            \n",
    "\n",
    "    for j in range(0, len(tmBatch2)):\n",
    "        inputs = tmBatch2[j]\n",
    "        weights = [[.15, 0.20, .21, .12, .21, .15, 0.20, .05, .087, .04, .9, .07, .008], [.25, .30, .04, .9, .07, .008, .0043, .025, .001, .078, 0.25, .98, .5]]\n",
    "        biases = [.35]\n",
    "        out = dotProduct(inputs, weights, biases)\n",
    "        \n",
    "        hout = activation(out)\n",
    "        input2 = hout\n",
    "        weight2 = [.25, .45]\n",
    "        bias2 = [.21]\n",
    "\n",
    "        finalOutput = dotProduct(input2, weight2, bias2) \n",
    "\n",
    "        #relu functiona\n",
    "        foutput = activation(finalOutput)\n",
    "        \n",
    "        if j == (len(tmBatch2)-1):\n",
    "            ter = error(y_test.iloc[j].to_numpy(), foutput)\n",
    "    \n",
    "           \n",
    "    for j in range(0, len(tmBatch3)):\n",
    "        inputs = tmBatch3[j]\n",
    "        weights = [[.15, 0.20, .21, .12, .21, .15, 0.20, .05, .087, .04, .9, .07, .008], [.25, .30, .04, .9, .07, .008, .0043, .025, .001, .078, 0.25, .98, .5]]\n",
    "        biases = [.35]\n",
    "        out = dotProduct(inputs, weights, biases)\n",
    "\n",
    "        hout = activation(out)\n",
    "        input2 = hout\n",
    "        weight2 = [.25, .45]\n",
    "        bias2 = [.21]\n",
    "\n",
    "        finalOutput = dotProduct(input2, weight2, bias2) \n",
    "\n",
    "        #relu functiona\n",
    "        foutput = activation(finalOutput)\n",
    "\n",
    "    if j == (len(tmBatch3)-1):\n",
    "        ter = error(y_test.iloc[j].to_numpy(), foutput)\n",
    "\n",
    "    tAverageError.append(ter)\n",
    "    print(\"Averager error/loss in first epoch = \", tAverageError[e])\n",
    "    ter = 0\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "3dcfbafa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1c846adc070>]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#using matplorlib to draw train againt test data\n",
    "epochs = []\n",
    "for i in range(0, 100):\n",
    "    epochs.append(i)\n",
    "\n",
    "plt.plot(epochs, AverageError)\n",
    "plt.plot(epochs, tAverageError)\n",
    "# For mini batch"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
